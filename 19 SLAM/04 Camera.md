> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.87](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=94&selection=34,11,40,3&color=yellow)
> 在以相机为主的视觉 SLAM 中，**观测主要是指相机成像的过程**

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.87](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=94&selection=41,17,44,15&color=red)
> 在计算机中，一张照片由很多个像素组成，每个像素记录了色彩或亮度的信息。三维世界中的一个物体反射或发出的光线，穿过相机光心后，投影在相机的成像平面上。相机的感光器件接收到光线后，产生了测量值，就得到了像素，形成了我们见到的照片。

> 有关成像的过程可以参考 [摄像头成像原理](../14%20Camera/摄像头成像原理.md)

# 01 相机模型

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.89](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=96&selection=10,0,15,3&color=yellow)
> 相机将三维世界中的坐标点（单位为米）映射到二维图像平面（单位为像素）的过程能够用一个几何模型进行描述。这个模型有很多种，其中最简单的称为 **针孔模型**。针孔模型是很 **常用**，而且 **有效的模型**，它描述了一束光线通过针孔之后，在针孔背面投影成像的关系。

## 1.1 针孔相机

针孔相机的成像原理就是小孔成像：

![视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.89](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=96&rect=55,116,411,323&color=yellow)

以相机镜头的 $O-x-y-z$ 为坐标系，那么，我们有：

$$\dfrac{Z}{f} = -\dfrac{X}{X'} = -\dfrac{Y}{Y'} \tag{1}$$

简化上述式子，整理得：

$$X' = f\dfrac{X}{Z},\ Y' = f\dfrac{Y}{Z} \tag{2}$$

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.90](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=97&selection=180,15,193,1&color=yellow)
> 在相机中，我们最终获得的是一个个的像素，这需要在成像平面上对像进行采样和量化。为了描述传感器将感受到的光线转换成图像像素的过程，我们设在物理成像平面上固定着一个像素平面 $o-u-v$ 。

我们假设在像素平面上的一点 $P'$ 的 **像素坐标** 为 $\begin{bmatrix} u && v \end{bmatrix}^T$ 。需要注意：

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.91](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=98&selection=6,0,31,1&color=red)
> 像素坐标系¨通常的定义方式是：原点 $o′$ 位于图像的左上角，$u$ 轴向右与 $x$ 轴平行，$v$ 轴向下与 $y$ 轴平行。像素坐标系与成像平面之间，**相差了一个缩放和一个原点的平移**。

我们假设在 $u$ 上缩放了 $\alpha$ 倍，在 $v$ 上缩放了 $\beta$ 倍，同时，原点平移了 $[c_x\ \ c_y]^T$ ，那么， $P'$ 的坐标与像素坐标之间的关系为：

$$
\left\{
\begin{array}{}
u = \alpha X' + c_x \\
v = \beta Y' + c_y
\end{array}
\right. \tag{3}
$$

接着，我们带入 式 $(2)$ ，并令 $f_x = \alpha f$ , $f_y = \beta f$ ，那么：

$$
\left\{
\begin{array}{}
u = f_x \dfrac{X}{Z} + c_x \\
v = f_y \dfrac{Y}{Z} + c_y
\end{array}
\right. \tag{4}
$$

其中， $f$ 的单位为 $m$ ， $\alpha , \beta$ 的单位为 $px/m$ ，则 $f_x, f_y$ 的单位为 $px$ 。将其写成矩阵形式，我们得到：

$$
\begin{bmatrix}u \\ v \\ 1 \end{bmatrix} = \dfrac{1}{Z}
\begin{bmatrix}
f_x && 0 && c_x \\
0 && f_y && c_y \\
0 && 0 && 1
\end{bmatrix}
\begin{bmatrix} X \\ Y \\ Z \end{bmatrix}
\triangleq \dfrac{1}{Z}KP
\tag{5}$$

我们习惯将$Z$ 挪到左边，则：

$$Z\begin{bmatrix}u \\ v \\ 1 \end{bmatrix} =
\begin{bmatrix}
f_x && 0 && c_x \\
0 && f_y && c_y \\
0 && 0 && 1
\end{bmatrix}
\begin{bmatrix} X \\ Y \\ Z \end{bmatrix}
\triangleq KP\tag{6}$$

其中，我们把中间的矩阵 $K$ 成为相机的 **内参矩阵 (Camera Intrinsics)** 。

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.91](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=98&selection=353,1,356,2&color=red)
> 通常认为，相机的内参在出厂之后是固定的，不会在使用过程中发生变化。有的相机生产厂商会告诉你相机的内参，而有时需要你自己确定相机的内参，也就是所谓的标定

由于相机在运动， $P$ 的相机坐标应该是他的世界坐标 $P_w$ 根据相机位姿变换到相机坐标系下的结果。假设相机的位姿由其旋转矩阵 $R$ 和平移量 $t$ 来描述，且记其变换矩阵为 $T$ ，那么有：

$$Z\begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = KP = KT^{-1}P_w\tag{7}$$

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.92](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=99&selection=67,16,87,18&color=yellow)
> 其中，相机的位姿 $R$ , $t$ 又称为相机的 **外参数 （Camera Extrinsics）**。相比于不变的内参，外参会随着相机运动发生改变，同时也是 SLAM 中待估计的目标，代表着机器人的轨迹。

我们将式 $(7)$ 中的 $Z$ 挪回右边，那么，我们可以得到：

$$P_c = \dfrac{1}{Z} \begin{bmatrix} X \\ Y \\ Z \end{bmatrix} = \begin{bmatrix} X/Z \\ Y/Z \\ 1 \end{bmatrix}\tag{8}$$

其中， $P_c$ 为 **归一化坐标** ，他位于相机前方 $z = 1$ 处的平面上，该平面称为 **归一化平面** 。

## 5.2 畸变

### 5.2.1 理解

> [!PDF|important] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.92](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=99&selection=234,0,235,10&color=important)
> 为了获得好的成像效果，我们在相机的前方加了透镜。透镜的加入对成像过程中光线的传播会产生新的影响：
> 
> 1. 透镜自身的形状 **对光线传播的影响**
> 2. 是在机械组装过程中， **透镜和成像平面不可能完全平行**，这也会使得光线穿过透镜投影到成像面时的位置发生变化

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.93](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=100&selection=7,0,19,4&color=yellow)
> 由 **透镜形状引起的畸变** 称之为 **径向畸变**。在针孔模型中，一条直线投影到像素平面上还是一条直线。可是，在实际拍摄的照片中，摄像机的透镜往往使得真实环境中的一条直线 **在图片中变成了曲线**。**越靠近图像的边缘，这种现象越明显**。由于实际加工制作的透镜往往是中心对称的，这使得 **不规则的畸变通常径向对称**。它们主要分为两大类，**桶形畸变** 和 **枕形畸变**

![视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.93](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=100&rect=105,398,399,495&color=yellow)

> [!PDF|note] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.93](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=100&selection=34,0,35,32&color=note)
> 桶形畸变是 **随着图像放大率离光轴的距离增加而减小**，而 **枕形畸变却恰好相反**。在这两种畸变中，穿过图像中心和光轴有交点的直线还能保持形状不变。

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.93](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=100&selection=36,0,39,0&color=yellow)
> 除了透镜的形状会引入径向畸变外，在相机的组装过程中由于 **不能使得透镜和成像面严格平行** 也会引入 **切向畸变**

![视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.93](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=100&rect=85,142,395,310&color=yellow)

### 5.2.2 数学表达

我们将平面上一点的坐标写成极坐标形式 $[r\ \ \theta]^T$ ，其中 $r$ 代表点 $p$ 里坐标原点的距离， $\theta$ 代表和水平轴的夹角。径向畸变可以看成是 **坐标点沿着长度方向** 发生了变化 $\Delta r$ ，切向畸变可以看成坐标点 **沿着切线方向** 发生了变化，也就是水平夹角发生了变化 $\Delta\theta$ 。

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.94](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=101&selection=37,0,41,21&color=red)
> 对于 **径向畸变**，无论是桶形畸变还是枕形畸变，由于它们都是 **随着离中心的距离增加而增加**。我们可以用一个多项式函数来描述畸变前后的坐标变化：这类畸变可以用和距中心距离有关的二次及高次多项式函数进行纠正：

$$\begin{array}{} x_c = x(1 + k_1r^2 + k_2r^4 + k_3r^6) \\ 
y_c = y(1 + k_1r^2 + k_2r^4 + k_3r^6)\end{array}\tag{9}$$

其中， $[x\ \ y]^T$ 是未纠正的点的坐标， $[x_c\ \ y_c]^T$ 是纠正过后点的坐标，他们都应该是 **归一化平面上的点** 而不是像素平面上的点。

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.94](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=101&selection=125,10,142,3&color=red)
> 对于畸变较小的图像 **中心区域**，畸变纠正主要是 $k_1$ 起作用。而对于畸变较大的 **边缘区域** 主要是 $k_2$ 起作用。普通摄像头用这两个系数就能很好的纠正径向畸变。对 **畸变很大的摄像头**，比如鱼眼镜头，可以加入 $k_3$ 畸变项对畸变进行纠正。

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.94](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=101&selection=143,5,153,1&color=red)
> 对于切向畸变，可以使用另外的两个参数 $p_1$ , $p_2$ 来进行纠正:

$$\begin{array}{} x_c = x + 2p_1xy + p_2(r^2 + 2x^2) \\
y_c = y + p_1(r^2 + 2y^2) + 2p_2xy \end{array}\tag{10}$$

联合式 $(9)(10)$ ，对于相机坐标系中的一点 $P_c(X, Y, Z)$ ，我们能够通过这五个畸变系数来找到这个点在像素平面上的正确位置：

1. 将三维空间中的点 $P_w$ 转换到相机坐标系 $P$ ，并将相机坐标系上的点投影到归一化平面，得到 $P_c = (x, y)$ 
2. 对归一化平面上的点进行径向畸变和切向畸变的矫正
   $$\left\{\begin{array}{}x_c = x(1 + k_1r^2 + k_2r^4 + k_3r^6) + 2p_1xy + p_2(r^2 + 2x^2) \\
   y_c = y(1 + k_1r^2 + k_2r^4 + k_3r^6) + p_1(r^2 + 2y^2) + 2p_2xy \end{array}\right.\tag{11}$$

3. 将纠正后的点通过内参矩阵投影到像素平面，得到该点在图像上的正确位置
   $$\left\{\begin{array}{}
   u = f_xx_c + c_x \\
   v = f_yy_c + c_y
   \end{array}\right. \tag{12}$$

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.95](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=102&selection=25,0,33,2&color=red)
> 值得一提的是，存在两种 **去畸变处理**（Undistort，或称 **畸变校正**）做法。我们可以选择先 **对整张图像进行去畸变**，得到去畸变后的图像，然后 **讨论此图像上的点的空间位置**。或者，我们也可以 **先考虑图像中的某个点**，然后按照去畸变方程，**讨论它去畸变后的空间位置**。

## 5.3 双目模型

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.95](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=102&selection=166,0,167,30&color=yellow)
> 测量像素距离（或深度）的方式有很多种，像人眼就可以根据左右眼看到的景物差异 （或称视差）来判断物体与我们的距离。双目相机的原理亦是如此。

单目相机示意图：

![视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.96](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=103&rect=72,409,443,560&color=yellow)

而双目相机则可以通过图像之间的像素差来估计每一个像素的深度：

![视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.96](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=103&rect=65,149,452,305&color=yellow)

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.97](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=104&selection=13,0,31,10&color=yellow)
> 双目相机一般由左眼和右眼两个水平放置的相机组成。当然也可以做成上下两个目， 但我们见到的主流双目都是做成左右的。在左右双目的相机中，我们可以把两个相机都看作针孔相机。它们是水平放置的，意味两个相机的光圈中心都位于 x 轴上。它们的距离称为 **双目相机的基线**（**Baseline**, 记作 $b$），是双目的重要参数。

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.97](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=104&selection=32,0,71,0&color=red)
> 现在，考虑一个空间点 $P$ ，它在左眼和右眼各成一像，记作 $P_L$ , $P_R$ 。由于相机基线的存在，这两个成像位置是不同的。理想情况下，由于左右相机只有在 x 轴上有位移，因此 $P$ 的像也只在 x 轴（对应图像的 $u$ 轴）上有差异。我们记它在左侧的坐标为 $u_L$，右侧坐标为 $u_R$ 。

根据几何关系：

$$\dfrac{z - f}{z} = \dfrac{b - u_L + u_R}{b}\tag{13}$$

整理得：

$$z = \dfrac{fb}{d},\ d = u_L - u_R\tag{14}$$

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.97](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=104&selection=157,0,175,37&color=red)
> 这里 $d$ 为 **左右图** 的 **横坐标之差**，称为 **视差（Disparity）**。根据视差，我们可以估计一个像素离相机的距离。
> 
> **视差与距离成反比**：视差越大，距离越近。同时，由于 **视差最小为一个像素**，于是双目的 **深度存在一个理论上的最大值**，由 $fb$ 确定。我们看到，当基线越长时，双目最大能测到的距离就会变远；反之，小型双目器件则只能测量很近的距离。

> [!PDF|important] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.97](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=104&selection=176,0,194,4&color=important)
> 虽然由视差计算深度的公式很简洁，但视差 d 本身的计算却比较困难。我们需要确切地知道左眼图像某个像素出现在右眼图像的哪一个位置（即对应关系），这件事亦属于“人类觉得容易而计算机觉得困难”的事务。当我们想计算每个像素的深度时，其计算量与精度都将成为问题，而且只有在图像纹理变化丰富的地方才能计算视差。由于计算量的原因， 双目深度估计仍需要使用 GPU 或 FPGA 来计算。

## 5.4 RGB-D 相机模型

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.97](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=104&selection=202,0,210,12&color=yellow)
> 相比于双目相机通过视差计算深度的方式，RGB-D 相机的做法更为“主动”一些，它能够 **主动测量每个像素的深度**。目前的 RGB-D 相机按原理可分为两大类：

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.97](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=104&selection=212,0,231,2&color=yellow)
> 1. 通过 **红外结构光**（**Structured Light**）来测量像素距离的。例子有 Kinect 1 代、Project Tango 1 代、Intel RealSense 等；

> [!PDF|yellow] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.98](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=105&selection=40,0,55,5&color=yellow)
> 2. 通过 **飞行时间法**（**Time-of-flight, ToF**）原理测量像素距离的。例子有 Kinect 2 代和一些现有的 ToF 传感器等。

> [!PDF|red] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.98](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=105&selection=87,0,98,2&color=red)
> 在测量深度之后，RGB-D 相机通常按照生产时的各个相机摆放位置，自己完成深度与彩色图像素之间的配对，输出一一对应的彩色图和深度图。我们可以在同一个图像位置， 读取到色彩信息和距离信息，计算像素的 3D 相机坐标，生成 **点云**（**Point Cloud**）。

> [!PDF|important] [视觉SLAM十四讲 从理论到实践_高翔; 张涛; 等, p.99](19%20SLAM/视觉SLAM十四讲%20从理论到实践_高翔;%20张涛;%20等.pdf#page=106&selection=16,0,31,17&color=important)
> RGB-D 相机能够实时地测量每个像素点的距离。但是，由于这种发射-接受的测量方式，使得它使用范围比较受限。用红外进行深度值测量的 RGB-D 相机，容易受到日光或其他传感器发射的红外光干扰，因此不能在室外使用，同时使用多个时也会相互干扰。对于透射材质的物体，因为接受不到反射光，所以无法测量这些点的位置。此外，RGB-D 相机在成本、功耗方面，都有一些劣势。
